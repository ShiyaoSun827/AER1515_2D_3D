import cv2
import numpy as np
import torch

from main import YOLOPv2                     # ä½ çš„ YOLOPv2 å°è£…
from smoke.config import cfg                 # SMOKE çš„ config
from smoke.modeling.detector import build_detection_model
from smoke.utils.check_point import DetectronCheckpointer

# ===================== 0. ä» KITTI calib è¯»å–å†…å‚ K =====================

def load_k_from_kitti_calib(calib_file):
    """
    ä» KITTI æ ‡å®šæ–‡ä»¶ä¸­è¯»å– P2ï¼Œå¹¶å–å…¶å‰ 3x3 ä½œä¸ºè¿‘ä¼¼çš„ç›¸æœºå†…å‚ Kã€‚

    calib æ–‡ä»¶æ ¼å¼å¤§æ¦‚æ˜¯ï¼š
        P0: ...
        P1: ...
        P2: fx 0 cx 0 fy cy 0 0 1 ...
        ...
    æˆ‘ä»¬åªå– P2 åé¢çš„ 12 ä¸ªæ•°ï¼Œreshape æˆ 3x4ï¼Œå†æ‹¿å‰ 3x3ã€‚
    """
    with open(calib_file, "r") as f:
        lines = f.readlines()

    P2 = None
    for line in lines:
        if line.startswith("P2:"):
            # å»æ‰ 'P2:' ç„¶åæŒ‰ç©ºæ ¼æ‹†åˆ†
            parts = line.strip().split()[1:]  # ä¸¢æ‰ 'P2:'
            vals = [float(p) for p in parts]
            if len(vals) != 12:
                raise RuntimeError(f"P2 è¡Œé•¿åº¦ä¸æ˜¯ 12: got {len(vals)}")
            P2 = np.array(vals, dtype=np.float32).reshape(3, 4)
            break

    if P2 is None:
        raise RuntimeError(f"åœ¨æ ‡å®šæ–‡ä»¶ {calib_file} ä¸­æ²¡æœ‰æ‰¾åˆ° P2 è¡Œ")

    K = P2[:, :3]  # å–å‰ 3x3
    return K  # (3,3)


# ===================== 1. YOLOPv2 åˆå§‹åŒ– =====================
yolop_model_path = "yolopv2_Nx3x480x640.onnx"
yolop = YOLOPv2(yolop_model_path, confThreshold=0.5)


# ===================== 2. SMOKE å°è£… =====================
class SmokeWrapper:
    """
    ç®€å•å°ä¸€å±‚ï¼Œæä¾›ä¸€ä¸ª infer_single_frame(frame_bgr) æ¥å£ï¼š
    - è¾“å…¥ï¼šOpenCV BGR å›¾åƒ (H, W, 3)
    - è¾“å‡ºï¼šdetections: List[np.ndarray]ï¼Œæ¯ä¸ª p å‘é‡ä¸€æ¡æ£€æµ‹
        p[0]  : cls_id (0=Car,1=Cyclist,2=Pedestrian)
        p[1]  : alpha
        p[2:6]: 2D bbox [left, top, right, bottom]
        p[6:9]: 3D dims [h, w, l]
        p[9:12]: 3D location [x, y, z] (camera coord)
        p[12]: rotation_y
        p[13]: score
    """
    def __init__(self, config_file, ckpt_path=None, kitti_calib_file=None):
        # è½½å…¥é…ç½®
        cfg.merge_from_file(config_file)
        cfg.freeze()

        self.cfg = cfg
        self.device = torch.device(cfg.MODEL.DEVICE)

        # ========== 2.1 è¯»å– KITTI çš„ K ==========
        if kitti_calib_file is not None:
            K_np = load_k_from_kitti_calib(kitti_calib_file)
        else:
            # å¦‚æœä½ æ²¡ç»™ calibï¼Œå°±å…ˆç”¨ä¸€ä¸ªå•ä½çŸ©é˜µå ä½ï¼ˆä¸æ¨èï¼‰
            K_np = np.eye(3, dtype=np.float32)
        # å­˜æˆ tensorï¼Œæ–¹ä¾¿åé¢ç”¨æ¥æŠ•å½± 3D æ¡†
        self.K = torch.from_numpy(K_np).to(self.device)  # (3,3)

        # ========== 2.2 æ„å»º SMOKE æ¨¡å‹ ==========
        self.model = build_detection_model(cfg).to(self.device)
        self.model.eval()

        # åŠ è½½æƒé‡ï¼Œé€»è¾‘è·Ÿ plain_train_net/test ä¸€è‡´
        checkpointer = DetectronCheckpointer(cfg, self.model, save_dir=cfg.OUTPUT_DIR)
        ckpt = ckpt_path if ckpt_path is not None else cfg.MODEL.WEIGHT
        _ = checkpointer.load(ckpt, use_latest=ckpt_path is None)

    @torch.no_grad()
    def infer_single_frame(self, frame_bgr):
        """
        è¿”å›ï¼šlist(np.ndarray)ï¼Œæ¯ä¸ª shape=(D,) çš„å‘é‡ p
        æ³¨æ„ï¼šè¿™é‡Œçš„é¢„å¤„ç†æ˜¯ä¸€ä¸ªâ€œç®€åŒ–ç‰ˆâ€ï¼Œä¸¥æ ¼æ¥è¯´åº”è¯¥å¤ç”¨ SMOKE çš„
        æ•°æ®å¢å¼º/å½’ä¸€åŒ–æµç¨‹ï¼Œä½ å¯ä»¥æ ¹æ® data/datasets é‡Œçš„å®ç°è¿›ä¸€æ­¥å¯¹é½ã€‚
        """
        img_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        img = img_rgb.astype(np.float32) / 255.0  # ç®€å•å½’ä¸€åŒ–åˆ° [0,1]

        # HWC -> CHW
        img_chw = img.transpose(2, 0, 1)
        img_tensor = torch.from_numpy(img_chw).unsqueeze(0).to(self.device)

        # è¿™é‡Œ targets åœ¨æ¨ç†æ—¶å¯ä»¥ä¼  None
        # ç›®å‰æˆ‘ä»¬æ²¡æœ‰æŠŠ K å–‚è¿›å»æ¨¡å‹ï¼Œå› ä¸ºä½ åŸç‰ˆçš„ test_net/inference
        # ä¹Ÿæ˜¯ç›´æ¥ model(images, targets)ï¼Œè¯´æ˜ K è¦ä¹ˆæ˜¯ bake åœ¨æ•°æ®é‡Œï¼Œ
        # è¦ä¹ˆæ¨¡å‹å†…éƒ¨ä¸æ˜¾å¼ç”¨ Kã€‚è¿™é‡Œå…ˆè·ŸåŸå®ç°ä¿æŒä¸€è‡´ã€‚
        outputs = self.model(img_tensor, targets=None)

        # æ ¹æ® inference.py çš„ç”¨æ³•ï¼Œoutputs æ”¯æŒ .to(cpu) å¹¶å¯è¢« for p in outputs éå†
        outputs_cpu = outputs.to(torch.device("cpu"))

        detections = []
        for p in outputs_cpu:
            # p æ˜¯ 1D tensorï¼Œä¸€æ¡æ£€æµ‹
            p_np = p.numpy()
            detections.append(p_np)

        return detections


# ===================== 3. åœ¨å›¾åƒä¸Šç”» SMOKE çš„ 2D BBox =====================
ID_TYPE_CONVERSION = {
    0: 'Car',
    1: 'Cyclist',
    2: 'Pedestrian'
}

def draw_smoke_boxes_2d(frame, detections, score_thresh=0.3):
    """
    åªåŸºäº SMOKE çš„ 2D bbox å’Œ score å åŠ åˆ°å›¾åƒä¸Šï¼Œç®€å•å¯é ã€‚
    åŒæ—¶æŠŠ 3D å‚æ•°ä¹Ÿé¡ºä¾¿è§£æå‡ºæ¥ï¼Œæ–¹ä¾¿ä½ åç»­ç”» 3D çº¿æ¡†/åš BEVã€‚
    """
    for p in detections:
        if p.shape[0] < 14:
            # é˜²å¾¡ï¼šç»´åº¦ä¸å¤Ÿå°±è·³è¿‡
            continue
        cls_id = int(p[0])
        alpha  = float(p[1])
        left, top, right, bottom = p[2:6]
        h, w, l = p[6:9]
        x, y, z = p[9:12]
        ry      = float(p[12])
        score   = float(p[13])

        if score < score_thresh:
            continue

        # ç”» 2D bbox
        pt1 = (int(left), int(top))
        pt2 = (int(right), int(bottom))
        color = (0, 255, 255)   # é»„ä¸€ç‚¹ï¼Œå’Œ YOLO çš„æ¡†åŒºåˆ†
        cv2.rectangle(frame, pt1, pt2, color, 2)

        # æ–‡å­—ï¼šç±»åˆ« + score
        cls_name = ID_TYPE_CONVERSION.get(cls_id, str(cls_id))
        text = f"{cls_name} {score:.2f}"
        cv2.putText(frame, text, (pt1[0], max(0, pt1[1]-5)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        # 3D å‚æ•° (h,w,l,x,y,z,ry) ä½ åç»­å¯ä»¥é…åˆ self.K åš 3D box æŠ•å½±
    return frame


# ===================== 4. åˆå§‹åŒ– SMOKE =====================
smoke_config_file = "configs/smoke_gn_vector.yaml"  # ä½ çš„ SMOKE é…ç½®
smoke_ckpt = "/Users/shiyaosun/Desktop/uoft_course/AER1515_project/Initial_result/Project/model_final.pth"

# ğŸ‘‰ è¿™é‡Œå¡«ä¸€ä»½ KITTI çš„ calib æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ï¼š
#    kitti_root/training/calib/000000.txt
kitti_calib_file = "/Users/shiyaosun/Desktop/uoft_course/AER1515_project/Initial_result/Project/kitti/testing/calib/000000.txt"

smoke = SmokeWrapper(
    smoke_config_file,
    ckpt_path=smoke_ckpt,
    kitti_calib_file=kitti_calib_file
)

# ===================== 5. è§†é¢‘è¯»å†™ & ä¸»å¾ªç¯ =====================
input_video_path = "input.mp4"
output_video_path = "output_yolop_smoke.mp4"

cap = cv2.VideoCapture(input_video_path)
if not cap.isOpened():
    raise RuntimeError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {input_video_path}")

fps = cap.get(cv2.CAP_PROP_FPS) or 25
width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

frame_idx = 0
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # --- YOLOPv2ï¼š2D æ£€æµ‹ + åˆ†å‰² ---
    frame_yolo = yolop.detect(frame.copy())

    # --- SMOKEï¼š3D æ£€æµ‹ï¼ˆåœ¨åŸå§‹ frame ä¸Šè·‘ï¼‰ ---
    detections = smoke.infer_single_frame(frame)

    # --- æŠŠ SMOKE çš„æ£€æµ‹ç”»åˆ° YOLO çš„ç»“æœå›¾ä¸Š ---
    frame_fused = draw_smoke_boxes_2d(frame_yolo, detections, score_thresh=0.3)

    out.write(frame_fused)

    cv2.imshow("YOLOPv2 + SMOKE", frame_fused)
    if cv2.waitKey(1) & 0xFF == 27:  # ESC é€€å‡º
        break

    frame_idx += 1

cap.release()
out.release()
cv2.destroyAllWindows()

print(f"å¤„ç†å®Œæˆï¼Œå…± {frame_idx} å¸§ï¼Œè¾“å‡ºä¿å­˜åˆ°: {output_video_path}")
